---
title: "P8130 Final Project, Exploratory Analyses"
author: "James Dalgleish"
date: "December 7, 2018"
output: html_document
---

```{r setup, include=FALSE, fig.height=20, fig.width = 20}
knitr::opts_chunk$set(echo = TRUE, cache = T)
library(tidyverse)
library(glmnet)
library(covTest)
```
```{r data_import}
can_reg <- read_csv("Cancer_Registry.csv") 
  
#this is the same file, but the n in Dona ana county has been changed to remove the n~ and allow processing.
skimr::skim_with(numeric = list(hist = NULL,min = min,max = max,kurtosis = e1071::kurtosis,skewness = e1071::skewness,IQR = IQR,
                                mean = mean,
                                cv = function(x){sd(x, na.rm = T)/mean(x, na.rm = T)}
                                ))
skimr::skim_with_defaults() #if having trouble with the above, try this or just subset teh columns that you  wish to skim.
can_reg %>% skimr::skim() #should replace the skimr results with the cleaned dataset.
Amelia::missmap(can_reg)
can_reg[,c(1,2,4:8,11:12,14:17,19:21,23:24,26:34)] %>% GGally::ggpairs()
corrplot::corrplot(cor(can_reg[sapply(can_reg,is.numeric)]))
```
We'll find that several variables have a great deal of missing data. In particular PctSomeCol18_24, PctPublicCoverage, PctEmployed16_Over, PctPrivateCoverageAlone all have missing data, which will decrease our sample size by 161 at minimum (columns 18, 22, 25, 27 of the original dataset).
Column 9 (binnedInc) is a factor, as is column 13 (county). Pct unemployed presents similar information to the percent employed, so we could choose to include the percent employed rather than the unemployed percetange.
```{r lasso}
can_reg_lasso <- glmnet(x = as.matrix(can_reg[,c(1,2,4:8,11:12,14:17,19:21,23:24,26:34)]),y = can_reg$TARGET_deathRate, alpha = 1)
```

```{r education}
education_cols <- can_reg[,c(16:21)]
skimr::skim_with_defaults()
education_cols %>% skimr::skim()
```
Looking at the skim results, it seems we may want to transform PctBachDeg18_24.
Despite these varaiables being the most skewed, it seems that the variables having to do with a bachelor's degree tend to be much more correlated with the outcome.

```{r correlations}
all_pairwise_corr_sorted <- cor(can_reg[sapply(can_reg,is.numeric)]) %>% 
  reshape2::melt(value.name = "correlation") %>%
  janitor::clean_names() %>% 
  filter(var1 != var2) %>% #need to remove duplicate entries of A->B and B->A 
#  head(10) %>% 
  arrange(-correlation)
all_pairwise_corr_sorted
target_corr <- cor(can_reg[sapply(can_reg,is.numeric)]) %>% 
  reshape2::melt(value.name = "correlation") %>%
  janitor::clean_names() %>% 
  filter(var1 != var2) %>% #need to remove duplicate entries of A->B and B->A 
#  head(10) %>% 
  filter(var1 == "TARGET_deathRate") %>% 
  arrange(-correlation)
  target_corr
```
It seems quite obvious that we should correct for the incidence rate as a potential confounder. The cancer death rate should be obviously influenced by the cancer incidence rate. It would be interesting to see if there are certain subsets of the data where this trend is not so strong (where treatments are better, perhaps).

The type of insurance seems to have a relationship with the death rate, although this may be an indicator of poverty or age/disability status (medicaid is only available to the elderly and disabled, typically).  If we examine this, we may want to include some age variable at the very least.

Poverty tends to have a stronger relationship than income, so this may suggest that binning along important lines can tell us more than simply using a raw continuous variable.

The percentage of those who only attain a high school education at the age of 25 in a given region seems to also be a very important variable, more than other indicators of education.

We may want to see which variables tend to be most correlated with others, with regard to educational status.

A side note about age: A binned age variable could possibly be used, as geriatric communities may have differing levels of income and public health coverage. Age itself might be viewed as a confounder as well.

```{r}
  target_abs_corr <- cor(can_reg[sapply(can_reg,is.numeric)]) %>% 
  reshape2::melt(value.name = "correlation") %>%
  janitor::clean_names() %>% 
  filter(var1 != var2) %>% #need to remove duplicate entries of A->B and B->A 
#  head(10) %>% 
  filter(var1 == "TARGET_deathRate") %>% 
  mutate(abs_corr = abs(correlation)) %>% 
  arrange(-abs_corr)
  target_abs_corr

```

Using the absolute value of correlation, we find that actually the percentage of individuals with a bachelor's degree has an even stronger degree of association with the cancer death rate than even cancer incidence. Pretty profound!
PctHS25_Over lags behind several other predictors, but still makes the top 10. To avoid multicollinearity, we should probably only choose one variable or at least not all of them.
The below filtered inter-variable correlations show that indeed this is the case.
```{r edu_multicollinearity}
all_pairwise_corr_sorted %>% 
  filter(var1 %in% names(education_cols))
```

```{r diagnostics}
educ<- lm(data = can_reg, as.formula(paste("TARGET_deathRate ~",paste(names(education_cols),collapse=" + "))))
#str_c(names(education_cols),collapse = "")
# educ<-lm(data = can_reg, formula =  target_DeathRate ~ PctNoHS18_24 + PctHS18_24 + PctSomeCol18_24 +
#    PctBachDeg18_24 + PctHS25_Over + PctBachDeg25_Over)
plot(educ)
```
the diagnostics look a bit imperfect. We'll recall that PctBachDeg18_24,  PctBachDeg25_Over, and PctNoHS18_24 were all skewed in distribution. We should apply a boxcox transformation to determine the correct transformations to take for each of these variables.
```{r transformed_lm_diags_educ}
educ_log<-lm(data = na.omit(can_reg), formula =  TARGET_deathRate ~ log(PctNoHS18_24 + 1e-2) + PctHS18_24 + PctSomeCol18_24 +
   log(PctBachDeg18_24 + 1e-2) + PctHS25_Over + log(PctBachDeg25_Over + 1e-2))

plot(educ_log)
```

```{r res_vs_obs}
can_reg_age <- lm(data=can_reg, TARGET_deathRate ~ MedianAge)
plot(can_reg$MedianAge[can_reg$MedianAge < 100],can_reg_age$residuals[can_reg$MedianAge < 100])
```
```{r}
can_reg_over_100<- can_reg %>%
  as.tibble() %>% 
  filter(MedianAge > 100) 
can_reg_over_100[,c("Geography","MedianAge")]

can_reg_over_100_female <- can_reg %>%
  as.tibble() %>% 
  filter(MedianAgeFemale > 100) 
can_reg_over_100_male <- can_reg %>%
  as.tibble() %>% 
  filter(MedianAgeMale > 100) 

can_reg_over_100[,c("Geography","MedianAge")]

```


```{r married}
all_pairwise_corr_sorted %>%
  filter(var1 %in% c("PercentMarried","PctMarriedHouseholds"))
```

```{r adding_state_vars}
region_table<- tibble::tibble(state.name,state.abb,state.region)
#get state variable from county.
#transform this to something that can be merged.
#merge on region data using state.
#can_reg$Geography
can_reg_state <- can_reg %>% 
  janitor::clean_names() %>% 
  tidyr::separate(geography, c("county","state"), sep=", ", remove = FALSE) %>% 
#  dplyr::select( county, state, geography, everything()) %>% 
  dplyr::left_join(region_table, by = c("state" = "state.name"))
#  merge(x = .,y = region_table, by.x="state",by.y = "state.name")
#Amelia::missmap(can_reg_state) #No new missing data from a bad merge.

setdiff(names(can_reg %>% janitor::clean_names()),names(can_reg_state))
setdiff(names(can_reg_state),names(can_reg %>% janitor::clean_names()))
```
```{r adding_incidence_rates, eval = F}
#add incidence rates from https://www.statecancerprofiles.cancer.gov/incidencerates/
# additional_cancer_cols <- list.files("can_inc", full.names = T) %>% 
#   map(read_csv, skip = 9, col_names = c("county","FIPS", "Met_Healthy_People_Objective", "Lower_95_Confidence_Interval", "Upper_95_Confidence_Interval", "Average_Annual_Count",
#                                          "Recent_Trend","Recent_5_Year_Trend_in_Incidence _Rates", "Lower_95_Confidence_Interval_5yr","Upper_95_Confidence_Interval_5yr"))
read_can_inc<-function(csvfile)
{
  inc_df <- read_csv(csvfile, skip = 8) %>% 
    janitor::clean_names() %>% 
    separate(county,into = c("county","state"), sep = ", ") %>% 
    mutate(state = str_replace(string = state, pattern = "\\(.*", replace = "")) %>%
    mutate(county = str_replace(string = county, pattern = "\\(.*", replace = "")) %>%
    mutate(cancer = str_replace(csvfile,pattern = ".csv","")) %>% 
    mutate(cancer = str_replace(cancer,pattern = "can_inc/","")) %>%
    mutate(incidence = age_adjusted_incidence_rate_u_0086_cases_per_100_000) %>% 
    dplyr::select(county,state,age_adjusted_incidence_rate_u_0086_cases_per_100_000,cancer) %>%  filter(!(county %in% c("","1","10","6","7","8")))
  colnames(inc_df)<-c("county","state","incidence","cancer")
  return(inc_df)
}
additional_cancer_cols <- list.files("can_inc", full.names = T) %>% 
map(read_can_inc)
names(additional_cancer_cols) <- list.files("can_inc") %>% gsub(x = .,pattern = ".csv",replacement = "")
# list.files("can_inc", full.names = T)[2] %>% read_csv(skip = 8)
# sapply(additional_cancer_cols,dim)
#  county_diff <- setdiff(additional_cancer_cols[[8]] %>% janitor::clean_names() %>% pull(county),
#            additional_cancer_cols[[1]] %>% janitor::clean_names() %>% pull(county))
#  counties_cbind <- rowr::cbind.fill(additional_cancer_cols[[4]] %>% janitor::clean_names() %>% pull(county) %>% sort(),
#            additional_cancer_cols[[1]] %>% janitor::clean_names() %>% pull(county) %>% sort()) 
#  colnames(counties_cbind) <- c("ovary","bladder")
#  counties_cbind %>% arrange(ovary,bladder)
# additional_cancer_cols <- list.files("can_inc", full.names = T) %>% 
# read_csv(file = "can_inc/bladder.csv", skip = 8)
#  county_diff <- setdiff(additional_cancer_cols[[1]] %>% janitor::clean_names() %>% pull(county),
#            additional_cancer_cols[[4]] %>% janitor::clean_names() %>% pull(county))
# additional_cancer_cols[[4]]
# can_reg_lung <- can_reg %>% 
#   janitor::clean_names() %>% 
#   separate(geography,into = c("county","state"), sep = ", ") %>% 
#   left_join(additional_cancer_cols[[6]], by=c("county" = "county", "state" = "state")) %>% 
#   mutate(incidence = as.numeric(incidence))
# plyr::join_all()
can_reg_joined <- can_reg_state
for(i in 1:length(additional_cancer_cols))
{
can_reg_joined <- can_reg_joined %>% 
  janitor::clean_names() %>% 
  separate(geography,into = c("county","state"), sep = ", ", remove = F) %>% 
  left_join(additional_cancer_cols[[i]], by=c("county" = "county", "state" = "state")) %>% 
  mutate(incidence = as.numeric(incidence)) %>% 
  dplyr::select(-cancer)
  names(can_reg_joined) <- gsub(pattern = "^incidence$",replacement = paste0(names(additional_cancer_cols)[i]),x = names(can_reg_joined))
  #mutate(paste0(names(additional_cancer_cols)[i]) = incidence)
  
}
write_csv(x = can_reg_joined, path =   "can_reg_joined.csv")
```

```{r pick_lambda_based_on_cv}
#can_reg_joined
can_reg_lasso <- glmnet(x = as.matrix(can_reg[,c(1,2,4:8,11:12,14:17,19:21,23:24,26:34)]),y = can_reg$TARGET_deathRate, alpha = 1)
#X <- as.matrix(dat_state[,-4])
can_filt <- can_reg_joined %>% 
  janitor::clean_names() %>% 
    mutate(binned_inc = as.factor(binned_inc)) %>% 
  mutate(binned_inc = fct_reorder(.f = binned_inc,.x = med_income)) %>% 
#  mutate()
dplyr::select( -pop_est2015, -med_income, -avg_ann_count, -avg_deaths_per_year, -median_age,        -pct_no_hs18_24, -pct_hs18_24, -pct_bach_deg18_24,   -percent_married, -pct_employed16_over, -pct_private_coverage, -pct_private_coverage_alone, -pct_emp_priv_coverage, -pct_public_coverage, -pct_black, -pct_asian, -pct_other_race, -state_abb,  -county, -state, -geography)

#which(sapply(can_filt,is.character))
```

```{r ridge_regression}
X = as.matrix(can_filt %>% dplyr::select(-target_death_rate) %>% sapply(as.numeric) %>% na.omit())
Y = na.omit(can_filt)$target_death_rate
set.seed(1)

train<-sample(1:nrow(X),nrow(X)/2)

test<-(-train)

Y.test<-Y[test]
set.seed(2)
doParallel::registerDoParallel()
cv.out<-cv.glmnet(X[train,],Y[train], alpha=0,nfolds = nrow(X), parallel = TRUE)
plot(cv.out)
best.lambda<-cv.out$lambda.min
ridge.pred <- predict(cv.out,s=best.lambda,newx=X[test,])
mean((ridge.pred-Y.test)^2) #MSE
ridge3<-glmnet(X, Y, alpha=0, lambda=best.lambda)
# res_ridge_ls<- cbind(coef(mult.fit),coef(ridge3))
# colnames(res_ridge_ls) <- c("LS", "Ridge")
res_ridge <- coef(ridge3) 
res_ridge %>% as.matrix() %>% as.data.frame() %>% add_rownames() %>% as.tibble() %>% 
  mutate(abs_ridge = abs(s0)) %>% 
  arrange(-abs_ridge)
final_ridge<-ridge3
final_ridge$dev.ratio
#can_reg_lasso$beta %>% View

```
Not surprisingly, the individual incidence rates tend to dominate the coefficients of the model. We'll try it out. Alternatively. We could use the top incidence rate per county as a factor and that may not overwhelm the model too much.  Besides these, the state region tends to be one of the largest predictors, as does the average household size and and the percent of married households. The dev ratio upon this run is `r final_ridge$dev.ratio`. It does include some incidence data, so this may be somewhat expected.

```{r}
cancer_names <- list.files("can_inc") %>% gsub(x = ., pattern = ".csv", replacement = "")
#X[which.max()]
#colnames(X)[max.col(X[,cancer_names],ties.method="first")]
# can_filt$top_can <- colnames(can_filt[,cancer_names])[apply(can_filt[,cancer_names],1,which.max) %>% unlist()]
can_filt$top_can <- apply(can_filt[,cancer_names],1,which.max) %>% map(.x = ., .f = ~ifelse(length(.)==0,"none",cancer_names[.])) %>% unlist() %>% as.factor()
X = as.matrix(can_filt %>% dplyr::select(-target_death_rate, -brca, -uterine, -bladder, -ovary, -brca_cis, -cervix, -colorectal, -lungbronc, -melanoma, -ovary, -prostate) %>% sapply(as.numeric) %>% na.omit())
#Y = na.omit(can_filt)$target_death_rate
Y = as.matrix(can_filt %>% dplyr::select( -bladder, -ovary, -brca_cis,  -brca, -uterine, -cervix, -colorectal, -lungbronc, -melanoma, -ovary, -prostate) %>% sapply(as.numeric) %>% na.omit() %>% .[,"target_death_rate"])

set.seed(1)

train<-sample(1:nrow(X),nrow(X)/2)

test<-(-train)

Y.test<-Y[test]
set.seed(2)
doParallel::registerDoParallel()
cv.out<-cv.glmnet(x = X[train,],y = Y[train], alpha=0,nfolds = nrow(X), parallel = TRUE)
plot(cv.out)
best.lambda<-cv.out$lambda.min
ridge.pred <- predict(cv.out,s=best.lambda,newx=X[test,])
mean((ridge.pred-Y.test)^2) #MSE
ridge3<-glmnet(X, Y, alpha=0, lambda=best.lambda)
#res_ridge_ls<- cbind(coef(mult.fit),coef(ridge3))
res_ridge <- coef(ridge3) 
res_ridge %>% as.matrix() %>% as.data.frame() %>% add_rownames() %>% as.tibble() %>% 
  mutate(abs_ridge = abs(s0)) %>% 
  arrange(-abs_ridge)
final_ridge_no_inc <- ridge3
final_ridge_no_inc$dev.ratio

```
As we take it out, we find that it gains a much lower importance in ridge regression. state_region tends to be the variable with the greatest importance, oddly. I would tend to include it in the final model, based on what we've seen here. Race, median age, and number of clinical trials tends to be several orders of magnitude below the education and employement variables... perhaps suggesting that the variance in Y may be better explained by direct employability measures like education and birth rate (which may be somewhat redundant with average household size). Dev ratio for this model, with a categorical variable for the most common cancer is `r final_ridge_no_inc$dev.ratio`, slightly below the adjusted R^2 of the full model after filtering.
```{r lasso_regression}
X = as.matrix(can_filt %>% dplyr::select(-target_death_rate, -brca, -uterine, -bladder, -ovary, -brca_cis, -cervix, -colorectal, -lungbronc, -melanoma, -ovary, -prostate) %>% sapply(as.numeric) %>% na.omit())
#Y = na.omit(can_filt)$target_death_rate
Y = as.matrix(can_filt %>% dplyr::select( -bladder, -ovary, -brca_cis,  -brca, -uterine, -cervix, -colorectal, -lungbronc, -melanoma, -ovary, -prostate) %>% sapply(as.numeric) %>% na.omit() %>% .[,"target_death_rate"])

set.seed(1)

train<-sample(1:nrow(X),nrow(X)/2)

test<-(-train)

Y.test<-Y[test]
set.seed(2)
doParallel::registerDoParallel()
grid <- 10^seq(5,-2, length=100)

can_reg_lasso <- glmnet(x = X,y = Y, alpha = 1)
lasso1<- glmnet(X[train ,],Y[train], alpha =1, lambda =grid)
set.seed(2)
cv.out<-cv.glmnet(X[train,],Y[train])
plot(cv.out)
best.lambda<-cv.out$lambda.min
lasso2<- glmnet(X, Y, alpha =1, lambda=best.lambda)
coef(lasso2) %>% as.matrix() %>% as.data.frame() %>% add_rownames() %>% as.tibble() %>% mutate(abs_s0 = abs(s0)) %>% arrange(-abs_s0)
#coef(mult.fit)
final_lasso_no_inc <- lasso2
plot(lasso1)
final_lasso_no_inc$dev.ratio

```
Utilizing lasso, we find that we have almost  precisely the same model. The dev ratio is nearly identical, at `r final_lasso_no_inc$dev.ratio`.

With a dev ratio of `r final_lasso_no_inc$dev.ratio`, this might be a reasonable model... but there may be far better ones from standard linear regression. We'll compare using R^2.  We'll perform the same selection of inital variables as before, or we'll have a fair number of counties ending up with missing data.

```{r lm_comparison}
#can_reg_state_copy <- can_reg_state
#can_reg_state$
can_reg_state$state.region[can_reg_state$county=="District of Columbia"]<-"South"
can_reg_state_filtered <- can_reg_state %>% 
  janitor::clean_names() %>% 
dplyr::select( -pop_est2015, -med_income, -avg_ann_count, -avg_deaths_per_year, -median_age,        -pct_no_hs18_24, -pct_hs18_24, -pct_bach_deg18_24, -pct_some_col18_24,   -percent_married, -pct_employed16_over, -pct_private_coverage, -pct_private_coverage_alone, -pct_emp_priv_coverage, -pct_public_coverage, -pct_black, -pct_asian, -pct_other_race, -state_abb,  -county, -state, -geography)

full_lm <- lm(data = can_reg_state, target_death_rate ~ .)
can_reg_state_int_only <- lm(data = can_reg_state, target_death_rate ~ 0)
full_lm_filtered <- lm(data = can_reg_state_filtered, target_death_rate ~ .)
full_lm_filtered_int_only <- lm(data = can_reg_state_filtered, target_death_rate ~ 0)
full_lm_filtered %>% summary()
#Amelia::missmap(can_reg_state)
plot(full_lm_filtered)
full_lm_filtered_summary <- summary(full_lm_filtered)
full_lm_filtered_summary$r.squared
full_lm_filtered_summary$adj.r.squared
full_lm %>% summary() %>% .$r.squared
full_lm %>% summary() %>% .$adj.r.squared
```
We'll find that the lasso selected model only has a modest change (about 3%) to the adjusted R^2 from the full filtered model and may perform better on test data than the full model (may be less overfit). With absolutely no fitering, the R^2=1 and the adjusted R^2 cannot be calculated.
```{r both_selection}

both_model <- stats::step(full_lm_filtered_int_only,scope = list(
  lower=formula(full_lm_filtered_int_only), upper = formula(full_lm_filtered)
  ), direction='both')
#which(is.na(can_reg_state$state.region))
both_model$model
both_model %>% summary()
both_model %>% summary() %>% .$adj.r.squared
```
Doing the both selection, we'll find there's a single missing value for state_region. It should be obvious how to correct this. It's the district of columbia. Considering the state above and below the district are both considered to be in the "South" level (2), we'll assign the same region to it. The adjusted R^2 is so high ($R^2$ =`r both_model %>% summary() %>% .$adj.r.squared`), we might suspect it's overfit.
We'll also try an exhaustive method using criteria for Cp and adjusted R^2.
```{r leaps, eval = F}
#this crashes my R session. Moving on.
# leaps::leaps(x = can_reg_state_filtered %>% dplyr::select(-target_death_rate) %>% as.data.frame(), y = can_reg_state_filtered %>% pull(target_death_rate), nbest = 2, method = "Cp")
# leaps::leaps(x = can_reg_state_filtered %>% dplyr::select(-target_death_rate) %>% as.data.frame(), y = can_reg_state_filtered %>% pull(-target_death_rate), nbest = 2, method = "adjr2")

```
```{r lasso_diags}
#plotmo::plot_glmnet(final_lasso_no_inc, dev = "dev") #still having a couple issues with these. Feel free to try a different package if these don't work well.
#plotmo::plot_glmnet(final_ridge_no_inc, xvar = "dev")
#plot(final_ridge_no_inc, xvar = "lambda")
par(mfrow = c(2,2))
plot(full_lm_filtered)
par(mfrow = c(2,2))
plot(both_model)
#https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html

```
```{r outliers}
#from "both" model and full model
outlier_counties <- can_reg_state[c(1221,1336,282,2714,1059),c("state","county","pop_est2015")]
outlier_counties %>% knitr::kable()

#can_reg_state[can_reg_state$MedianAge > 100,] #median age no longer exists.
#no influence points.

```
The above shows that there are a few potential outliers that might be driving the model are those in madison county, MS; williamsburg city, VA; Crowley County, CO; Phillips county, KS; and the Aleutians West Census Area, AK. Almost all of them except for Madison County, MS are very low in population and are a potential outlier due to this particular variable. The cooks distance does not suggest any influence points
```{r vif, results='asis'}
faraway::vif(full_lm_filtered) %>% sort(decreasing = T)
faraway::vif(both_model) %>% sort(decreasing = T)
```
From the vif results, it seems as though the binned income is causing multicollinearity, as is having both median_age_male and median_age_female. Poverty Percent seems to be too highly related to income. At this point, we could remove one of the ages (male or female) and remove one of the income variables to see if this ameliorates the issue. A third option would be to do a PCA, as suggested in lecture 17.
```{r}
full_lm_filtered
```

```{r PCA}

#ade4::dudi.pca(df = as.matrix(sapply(can_reg_state_filtered,as.numeric)))
#FactoMineR::PCA( as.matrix(sapply(can_reg_state_filtered,as.numeric)))
# FactoMineR::PCA( can_reg_state_filtered %>% mutate(state_region = as.numeric(state_region)) %>% mutate(binned_inc = as.numeric(binned_inc)))
pca_can_reg_state_filtered <- stats::princomp(can_reg_state_filtered %>% mutate(state_region = as.numeric(state_region)) %>% mutate(binned_inc = as.numeric(as.factor(binned_inc))) %>% na.omit())
plot(pca_can_reg_state_filtered)
pca_can_reg_state_filtered$loadings
#pca_can_reg_state_filtered$scores
```
If we look at the amount of variance explained by PC1 and look at the loadings, we'll find relationships among the variables. Among them, female and age male age tend to put their variance into the same bins utilizing the same variables. Incidence and the target variable go together,                                                                                                                                                                                                                                                                                                                                                                                                        
```{r extra_pca, eval = F, echo = F}
PCA_can_reg_state_filtered <- can_reg_state_filtered %>% mutate(state_region = as.numeric(state_region)) %>% mutate(binned_inc = as.numeric(as.factor(binned_inc))) %>% na.omit() %>% FactoMineR::PCA()
#loadings <- PCA_can_reg_state_filtered$var$coord %>% as.data.frame()
#loadings %>% add_rownames() %>% .[order(-loadings$Dim.1),]
#prcomp_can_reg_state_filtered <- stats::prcomp(can_reg_state_filtered %>% mutate(state_region = as.numeric(state_region)) %>% mutate(binned_inc = as.numeric(as.factor(binned_inc))) %>% na.omit())
#prcomp_can_reg_state_filtered$rotation %>% as.data.frame() %>% add_rownames() %>% as.tibble() %>% mutate(abs_PC1 = abs(PC1)) %>% arrange(abs_PC1)
#plot(prcomp_can_reg_state_filtered)
#plot(PCA_can_reg_state_filtered)

```
Following this, we'll notice that in the Variables Factor Map, we'll see that the median age variables follow each other precisely. We will proceed to remove them.  There are a lot of other relationships. Unemployment seems to have a similar vector to poverty and the percent of public coverage alone seems to be in the same magnitude and direction as the target.
```{r multicollinearity_vif2}
faraway::vif(lm(full_lm_filtered$call$formula))
             can_reg_state_filtered %>% lm(data=.,formula = as.formula(paste0(  "target_death_rate ~ ", (can_reg_state_filtered %>% select(-median_age_male, -binned_inc) %>% names() %>% paste0(collapse= " + ")),collapse=""))) %>% faraway::vif() %>% sort(decreasing = T)
          can_reg_state_filtered_vif_reduced  <- can_reg_state_filtered %>% lm(data=.,formula = as.formula(paste0(  "target_death_rate ~ ", (can_reg_state_filtered %>% select(-median_age_male, -binned_inc, -pct_hs25_over) %>% names() %>% paste0(collapse= " + ")),collapse="")))
          can_reg_state_filtered_vif_reduced %>% summary() %>% .$adj.r.squared
          can_reg_state_filtered_vif_reduced %>% faraway::vif() %>% sort(decreasing = T)
```
By removing the the median male age and the percent of individuals over 25 with only a high school education, we find that our VIF values are below 5. As we add in further variables, we'll have to watch this and make sure it stays below this level. It's a reasonable model with an $R^2_{adj}$ = `r can_reg_state_filtered_vif_reduced %>% summary() %>% .$adj.r.squared`.
```{r partialr2}
#plot(anova(full_lm_filtered), 'partial R2')
```

```{r  elastic_net}

# res_ls_ridge_lasso<- cbind(coef(mult.fit),coef(ridge3),coef(lasso2))
# colnames(res_ls_ridge_lasso) <- c("LS", "Ridge","Lasso")
# res_ls_ridge_lasso

```

```{r assumptions}
#use covTest to get predictions
#get residuals
```


```{r}
# can_reg_state <-
# can_reg_state %>% 
#   janitor::clean_names()
# can_reg_state_filtered <- can_reg_state %>% 
#   janitor::clean_names() %>% 
# dplyr::select( -pop_est2015, -med_income, -avg_ann_count, -avg_deaths_per_year, -median_age,        -pct_no_hs18_24, -pct_hs18_24, -pct_bach_deg18_24, -pct_some_col18_24,   -percent_married, -pct_employed16_over, -pct_private_coverage, -pct_private_coverage_alone, -pct_emp_priv_coverage, -pct_public_coverage, -pct_black, -pct_asian, -pct_other_race, -state_abb,  -county, -state, -geography)

```

