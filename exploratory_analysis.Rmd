---
title: "P8130 Final Project, Exploratory Analyses"
author: "James Dalgleish"
date: "December 7, 2018"
output: html_document
---

```{r setup, include=FALSE, fig.height=20, fig.width = 20}
knitr::opts_chunk$set(echo = TRUE, cache = T)
library(tidyverse)
library(glmnet)
```
```{r data_import}
can_reg <- read_csv("Cancer_Registry.csv") 
  
#this is the same file, but the n in Dona ana county has been changed to remove the n~ and allow processing.
skimr::skim_with(numeric = list(hist = NULL,min = min,max = max,kurtosis = e1071::kurtosis,skewness = e1071::skewness,IQR = IQR,
                                mean = mean,
                                cv = function(x){sd(x, na.rm = T)/mean(x, na.rm = T)}
                                ))
skimr::skim_with_defaults() #if having trouble with the above, try this or just subset teh columns that you  wish to skim.
can_reg %>% skimr::skim()
Amelia::missmap(can_reg)
can_reg[,c(1,2,4:8,11:12,14:17,19:21,23:24,26:34)] %>% GGally::ggpairs()
corrplot::corrplot(cor(can_reg[sapply(can_reg,is.numeric)]))
```
We'll find that several variables have a great deal of missing data. In particular PctSomeCol18_24, PctPublicCoverage, PctEmployed16_Over, PctPrivateCoverageAlone all have missing data, which will decrease our sample size by 161 at minimum (columns 18, 22, 25, 27 of the original dataset).
Column 9 (binnedInc) is a factor, as is column 13 (county). Pct unemployed presents similar information to the percent employed, so we could choose to include the percent employed rather than the unemployed percetange.
```{r lasso}
can_reg_lasso <- glmnet(x = as.matrix(can_reg[,c(1,2,4:8,11:12,14:17,19:21,23:24,26:34)]),y = can_reg$TARGET_deathRate, alpha = 1)
```

```{r education}
education_cols <- can_reg[,c(16:21)]
skimr::skim_with_defaults()
education_cols %>% skimr::skim()
```
Looking at the skim results, it seems we may want to transform PctBachDeg18_24.
Despite these varaiables being the most skewed, it seems that the variables having to do with a bachelor's degree tend to be much more correlated with the outcome.

```{r correlations}
all_pairwise_corr_sorted <- cor(can_reg[sapply(can_reg,is.numeric)]) %>% 
  reshape2::melt(value.name = "correlation") %>%
  janitor::clean_names() %>% 
  filter(var1 != var2) %>% #need to remove duplicate entries of A->B and B->A 
#  head(10) %>% 
  arrange(-correlation)
all_pairwise_corr_sorted
target_corr <- cor(can_reg[sapply(can_reg,is.numeric)]) %>% 
  reshape2::melt(value.name = "correlation") %>%
  janitor::clean_names() %>% 
  filter(var1 != var2) %>% #need to remove duplicate entries of A->B and B->A 
#  head(10) %>% 
  filter(var1 == "TARGET_deathRate") %>% 
  arrange(-correlation)
  target_corr
```
It seems quite obvious that we should correct for the incidence rate as a potential confounder. The cancer death rate should be obviously influenced by the cancer incidence rate. It would be interesting to see if there are certain subsets of the data where this trend is not so strong (where treatments are better, perhaps).

The type of insurance seems to have a relationship with the death rate, although this may be an indicator of poverty or age/disability status (medicaid is only available to the elderly and disabled, typically).  If we examine this, we may want to include some age variable at the very least.

Poverty tends to have a stronger relationship than income, so this may suggest that binning along important lines can tell us more than simply using a raw continuous variable.

The percentage of those who only attain a high school education at the age of 25 in a given region seems to also be a very important variable, more than other indicators of education.

We may want to see which variables tend to be most correlated with others, with regard to educational status.

A side note about age: A binned age variable could possibly be used, as geriatric communities may have differing levels of income and public health coverage. Age itself might be viewed as a confounder as well.

```{r}
  target_abs_corr <- cor(can_reg[sapply(can_reg,is.numeric)]) %>% 
  reshape2::melt(value.name = "correlation") %>%
  janitor::clean_names() %>% 
  filter(var1 != var2) %>% #need to remove duplicate entries of A->B and B->A 
#  head(10) %>% 
  filter(var1 == "TARGET_deathRate") %>% 
  mutate(abs_corr = abs(correlation)) %>% 
  arrange(-abs_corr)
  target_abs_corr

```

Using the absolute value of correlation, we find that actually the percentage of individuals with a bachelor's degree has an even stronger degree of association with the cancer death rate than even cancer incidence. Pretty profound!
PctHS25_Over lags behind several other predictors, but still makes the top 10. To avoid multicollinearity, we should probably only choose one variable or at least not all of them.
The below filtered inter-variable correlations show that indeed this is the case.
```{r edu_multicollinearity}
all_pairwise_corr_sorted %>% 
  filter(var1 %in% names(education_cols))
```

```{r diagnostics}
educ<- lm(data = can_reg, as.formula(paste("TARGET_deathRate ~",paste(names(education_cols),collapse=" + "))))
#str_c(names(education_cols),collapse = "")
# educ<-lm(data = can_reg, formula =  target_DeathRate ~ PctNoHS18_24 + PctHS18_24 + PctSomeCol18_24 +
#    PctBachDeg18_24 + PctHS25_Over + PctBachDeg25_Over)
plot(educ)
```
the diagnostics look a bit imperfect. We'll recall that PctBachDeg18_24,  PctBachDeg25_Over, and PctNoHS18_24 were all skewed in distribution. We should apply a boxcox transformation to determine the correct transformations to take for each of these variables.
```{r transformed_lm_diags_educ}
educ_log<-lm(data = na.omit(can_reg), formula =  TARGET_deathRate ~ log(PctNoHS18_24 + 1e-2) + PctHS18_24 + PctSomeCol18_24 +
   log(PctBachDeg18_24 + 1e-2) + PctHS25_Over + log(PctBachDeg25_Over + 1e-2))

plot(educ_log)
```

```{r res_vs_obs}
can_reg_age <- lm(data=can_reg, TARGET_deathRate ~ MedianAge)
plot(can_reg$MedianAge[can_reg$MedianAge < 100],can_reg_age$residuals[can_reg$MedianAge < 100])
```
```{r}
can_reg_over_100<- can_reg %>%
  as.tibble() %>% 
  filter(MedianAge > 100) 
can_reg_over_100[,c("Geography","MedianAge")]

can_reg_over_100_female <- can_reg %>%
  as.tibble() %>% 
  filter(MedianAgeFemale > 100) 
can_reg_over_100_male <- can_reg %>%
  as.tibble() %>% 
  filter(MedianAgeMale > 100) 

can_reg_over_100[,c("Geography","MedianAge")]

```


```{r married}
all_pairwise_corr_sorted %>%
  filter(var1 %in% c("PercentMarried","PctMarriedHouseholds"))
```

```{r adding_state_vars}
region_table<- tibble::tibble(state.name,state.abb,state.region)
#get state variable from county.
#transform this to something that can be merged.
#merge on region data using state.
can_reg$Geography
can_reg_state <- can_reg %>% 
  janitor::clean_names() %>% 
  tidyr::separate(geography, c("county","state"), sep=", ", remove = FALSE) %>% 
#  dplyr::select( county, state, geography, everything()) %>% 
  dplyr::left_join(region_table, by = c("state" = "state.name"))
#  merge(x = .,y = region_table, by.x="state",by.y = "state.name")
#Amelia::missmap(can_reg_state) #No new missing data from a bad merge.

setdiff(names(can_reg %>% janitor::clean_names()),names(can_reg_state))
setdiff(names(can_reg_state),names(can_reg %>% janitor::clean_names()))
```
```{r adding_incidence_rates, eval = F}
#add incidence rates from https://www.statecancerprofiles.cancer.gov/incidencerates/
# additional_cancer_cols <- list.files("can_inc", full.names = T) %>% 
#   map(read_csv, skip = 9, col_names = c("county","FIPS", "Met_Healthy_People_Objective", "Lower_95_Confidence_Interval", "Upper_95_Confidence_Interval", "Average_Annual_Count",
#                                          "Recent_Trend","Recent_5_Year_Trend_in_Incidence _Rates", "Lower_95_Confidence_Interval_5yr","Upper_95_Confidence_Interval_5yr"))
read_can_inc<-function(csvfile)
{
  inc_df <- read_csv(csvfile, skip = 8) %>% 
    janitor::clean_names() %>% 
    separate(county,into = c("county","state"), sep = ", ") %>% 
    mutate(state = str_replace(string = state, pattern = "\\(.*", replace = "")) %>%
    mutate(county = str_replace(string = county, pattern = "\\(.*", replace = "")) %>%
    mutate(cancer = str_replace(csvfile,pattern = ".csv","")) %>% 
    mutate(cancer = str_replace(cancer,pattern = "can_inc/","")) %>%
    mutate(incidence = age_adjusted_incidence_rate_u_0086_cases_per_100_000) %>% 
    dplyr::select(county,state,age_adjusted_incidence_rate_u_0086_cases_per_100_000,cancer) %>%  filter(!(county %in% c("","1","10","6","7","8")))
  colnames(inc_df)<-c("county","state","incidence","cancer")
  return(inc_df)
}
additional_cancer_cols <- list.files("can_inc", full.names = T) %>% 
map(read_can_inc)
names(additional_cancer_cols) <- list.files("can_inc") %>% gsub(x = .,pattern = ".csv",replacement = "")
# list.files("can_inc", full.names = T)[2] %>% read_csv(skip = 8)
# sapply(additional_cancer_cols,dim)
#  county_diff <- setdiff(additional_cancer_cols[[8]] %>% janitor::clean_names() %>% pull(county),
#            additional_cancer_cols[[1]] %>% janitor::clean_names() %>% pull(county))
#  counties_cbind <- rowr::cbind.fill(additional_cancer_cols[[4]] %>% janitor::clean_names() %>% pull(county) %>% sort(),
#            additional_cancer_cols[[1]] %>% janitor::clean_names() %>% pull(county) %>% sort()) 
#  colnames(counties_cbind) <- c("ovary","bladder")
#  counties_cbind %>% arrange(ovary,bladder)
# additional_cancer_cols <- list.files("can_inc", full.names = T) %>% 
# read_csv(file = "can_inc/bladder.csv", skip = 8)
#  county_diff <- setdiff(additional_cancer_cols[[1]] %>% janitor::clean_names() %>% pull(county),
#            additional_cancer_cols[[4]] %>% janitor::clean_names() %>% pull(county))
# additional_cancer_cols[[4]]
# can_reg_lung <- can_reg %>% 
#   janitor::clean_names() %>% 
#   separate(geography,into = c("county","state"), sep = ", ") %>% 
#   left_join(additional_cancer_cols[[6]], by=c("county" = "county", "state" = "state")) %>% 
#   mutate(incidence = as.numeric(incidence))
# plyr::join_all()
can_reg_joined <- can_reg_state
for(i in 1:length(additional_cancer_cols))
{
can_reg_joined <- can_reg_joined %>% 
  janitor::clean_names() %>% 
  separate(geography,into = c("county","state"), sep = ", ", remove = F) %>% 
  left_join(additional_cancer_cols[[i]], by=c("county" = "county", "state" = "state")) %>% 
  mutate(incidence = as.numeric(incidence)) %>% 
  dplyr::select(-cancer)
  names(can_reg_joined) <- gsub(pattern = "^incidence$",replacement = paste0(names(additional_cancer_cols)[i]),x = names(can_reg_joined))
  #mutate(paste0(names(additional_cancer_cols)[i]) = incidence)
  
}
write_csv(x = can_reg_joined, path =   "can_reg_joined.csv")
```

```{r pick_lambda_based_on_cv}
#can_reg_joined
can_reg_lasso <- glmnet(x = as.matrix(can_reg[,c(1,2,4:8,11:12,14:17,19:21,23:24,26:34)]),y = can_reg$TARGET_deathRate, alpha = 1)
#X <- as.matrix(dat_state[,-4])
can_filt <- can_reg_joined %>% 
  janitor::clean_names() %>% 
    mutate(binned_inc = as.factor(binned_inc)) %>% 
  mutate(binned_inc = fct_reorder(.f = binned_inc,.x = med_income)) %>% 
#  mutate()
dplyr::select( -pct_some_col18_24, -pct_no_hs18_24, -pct_hs18_24, -pct_bach_deg18_24, -avg_ann_count,  -avg_deaths_per_year, -med_income, -pop_est2015, -median_age_male, -median_age_female, -percent_married, -pct_employed16_over, -pct_private_coverage, -pct_private_coverage_alone, -pct_emp_priv_coverage, -pct_public_coverage, -pct_black, -pct_asian, -pct_other_race, -state_abb, -incidence_rate, -county, -state, -geography)

#which(sapply(can_filt,is.character))
```

```{r ridge_regression}
X = as.matrix(can_filt %>% dplyr::select(-target_death_rate) %>% sapply(as.numeric) %>% na.omit())
Y = na.omit(can_filt)$target_death_rate
set.seed(1)

train<-sample(1:nrow(X),nrow(X)/2)

test<-(-train)

Y.test<-Y[test]
set.seed(2)
doParallel::registerDoParallel()
cv.out<-cv.glmnet(X[train,],Y[train], alpha=0,nfolds = nrow(X), parallel = TRUE)
plot(cv.out)
best.lambda<-cv.out$lambda.min
ridge.pred <- predict(cv.out,s=best.lambda,newx=X[test,])
mean((ridge.pred-Y.test)^2) #MSE
ridge3<-glmnet(X, Y, alpha=0, lambda=best.lambda)
res_ridge_ls<- cbind(coef(mult.fit),coef(ridge3))
colnames(res_ridge_ls) <- c("LS", "Ridge")
res_ridge_ls %>% as.matrix() %>% as.data.frame() %>% add_rownames() %>% as.tibble() %>% 
  mutate(abs_ridge = abs(Ridge)) %>% 
  arrange(-abs_ridge)

#can_reg_lasso$beta %>% View
```
Not surprisingly, the individual incidence rates tend to dominate the coefficients of the model. We'll try it out. Alternatively. We could use the top incidence rate per county as a factor and that may not overwhelm the model too much.  Besides these, the state region tends to be one of the largest predictors, as does the average household size and and the percent of married households.

```{r}
cancer_names <- list.files("can_inc") %>% gsub(x = ., pattern = ".csv", replacement = "")
#X[which.max()]
#colnames(X)[max.col(X[,cancer_names],ties.method="first")]
# can_filt$top_can <- colnames(can_filt[,cancer_names])[apply(can_filt[,cancer_names],1,which.max) %>% unlist()]
can_filt$top_can <- apply(can_filt[,cancer_names],1,which.max) %>% map(.x = ., .f = ~ifelse(length(.)==0,"none",cancer_names[.])) %>% unlist() %>% as.factor()
X = as.matrix(can_filt %>% dplyr::select(-target_death_rate, -brca, -uterine, -bladder, -ovary, -brca_cis, -cervix, -colorectal, -lungbronc, -melanoma, -ovary, -prostate) %>% sapply(as.numeric) %>% na.omit())
#Y = na.omit(can_filt)$target_death_rate
Y = as.matrix(can_filt %>% dplyr::select( -bladder, -ovary, -brca_cis,  -brca, -uterine, -cervix, -colorectal, -lungbronc, -melanoma, -ovary, -prostate) %>% sapply(as.numeric) %>% na.omit() %>% .[,"target_death_rate"])

set.seed(1)

train<-sample(1:nrow(X),nrow(X)/2)

test<-(-train)

Y.test<-Y[test]
set.seed(2)
doParallel::registerDoParallel()
cv.out<-cv.glmnet(x = X[train,],y = Y[train], alpha=0,nfolds = nrow(X), parallel = TRUE)
plot(cv.out)
best.lambda<-cv.out$lambda.min
ridge.pred <- predict(cv.out,s=best.lambda,newx=X[test,])
mean((ridge.pred-Y.test)^2) #MSE
ridge3<-glmnet(X, Y, alpha=0, lambda=best.lambda)
res_ridge_ls<- cbind(coef(mult.fit),coef(ridge3))
colnames(res_ridge_ls) <- c("LS", "Ridge")
res_ridge_ls %>% as.matrix() %>% as.data.frame() %>% add_rownames() %>% as.tibble() %>% 
  mutate(abs_ridge = abs(Ridge)) %>% 
  arrange(-abs_ridge)

```
As we take it out, we find that it gains a much lower importance in ridge regression. state_region tends to be the variable with the greatest importance, oddly. I would tend to include it in the final model, based on what we've seen here. Race, median age, and number of clinical trials tends to be several orders of magnitude below the education and employement variables... perhaps suggesting that the variance in Y may be better explained by direct employability measures like education and birth rate (which may be somewhat redundant with average household size).
```{r lasso_regression}
can_reg_lasso <- glmnet(x = X,y = Y, alpha = 1)
lasso1<- glmnet(X[train ,],Y[train], alpha =1, lambda =grid)
set.seed(2)
cv.out<-cv.glmnet(X[train,],Y[train])
plot(cv.out)
best.lambda<-cv.out$lambda.min
lasso2<- glmnet(X, Y, alpha =1, lambda=best.lambda)
coef(lasso2) %>% as.matrix() %>% as.data.frame() %>% add_rownames() %>% as.tibble() %>% mutate(abs_s0 = abs(s0)) %>% arrange(-abs_s0)
#coef(mult.fit)

```
Utilizing lasso, we find that we have almost  precisely the same model.
```{r diagnostics}
plot(lasso1)
#res vs fit
lasso2$dev.ratio

#
```

With a dev ratio of 0.36, this might be a reasonable model... but there may be far better ones from standard linear regression.

```{r  elastic_net}
full_model <- stats::lm(data = can_reg_state, target_death_rate ~ .)
full_model %>% summary()
res_ls_ridge_lasso<- cbind(coef(mult.fit),coef(ridge3),coef(lasso2))
colnames(res_ls_ridge_lasso) <- c("LS", "Ridge","Lasso")
res_ls_ridge_lasso

```

```{r assumptions}

```

```{r PCA}

```

